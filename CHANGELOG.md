# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added

- Inference body-tracking components:
  - Inference data processing from Magic XRoom
  - Emotion classification inference using model checkpoint (the checkpoint trained model is not using handcrafted features from the training tools)
- Fusion Layer support for multimodalities of XRoom dataset (bio-measurements and body-tracking modalities)
- Unittests for Fusion Layer component

### Changed

- Update mock writer to work with two modalities: shimmer and vr (body-tracking)
- Fusion Layer implementation for uni/multimodal: now take into account the data window (frequency * seq_len)
- Configuration file structure to encompass multimodality capability


## [0.6.0] - 2024 - 07 - 24

## Added

- Pre-processing component (Bio measurements modality): an additional component to read and process the data output
  files generated by the data collection tool [Magic XRoom](https://github.com/XR2Learn/magic-xroom), for the bio
  measurements modality. Additionally, this component publishes the processed data.
- Mock XRoom Writer component (Bio measurements modality): an additional component to support testing pre-processing
  component. ```Mock XRoom Writer``` mocks Magic XRoom behaviour of creating and editing files with data from data
  collection sessions.
- Communication between```Multimodal Fusion``` and ```Emotion Classification```components using pub/sub protocol.
- Integration of all Inference components (except ED evaluation) to support real-time communication via pub/sub
  messaging protocol (bio measurements modality).

## Changed

- ```Emotion Classification``` communication protocol. This component is now a pub/sub.

### Fixed

- Problem with "data_to_fusion" configuration under "inference_config", this option has been removed.

## [0.5.0] - 2024 - 04 - 09

## Added

- "modality" configuration required in addition to dataset name, under "dataset_configuration"
  on ```configuration.json``` file.
- MLP encoder for the audio modality (intended for eGeMAPS).
- Emotion classification component architecture for the body tracking modality.

## Changed

- Bio-Measurements (BM) dataset name changed to 'XRoom', for data coming
  from [Magic XRoom](https://github.com/XR2Learn/magic-xroom).
- Output directory structure: Two additional directory levels to indicate the dataset/modality that produced the
  output (changes applied for audio and BM modalities).
- Output directory structure for reading trained encoders and models, according to Training Tools structure.

## Fixed

- Multimodal Layer component now supports BM modality (when acting as a publisher).

## Known Issues

- "data_to_fusion" configuration under "inference_config" is generating an error.

## [0.4.0] - 2024 - 03 - 12

### Added

- Support for bio-measurements (BM) modality using data format
  by [Magic XRoom](https://github.com/XR2Learn/magic-xroom).
- License Update to Apache 2.0.

### Known Issues

- Multimodal Layer component does not support BM modality (when acting as a publisher).

## [0.3.1] - 2024 - 02 - 15

### Added

- License
- More documentation

## [0.3.0] - 2024 - 01 - 19

### Added

- Multimodal fusion layer can be a publisher, i.e., the predicted emotion will be published to be read by
  the personalisation tool (optional).

## [0.2.0] - 2024 - 01 - 09

### Added

- End2End mode: use fine-tuned model (encoder + classifier) to make predictions from pre-processed data
- Unit tests for audio prediction components and github workflow for automated testing

### Changed

- Inference config structure. Required field: "mode"

## [0.1.1] - 2023 - 12 - 06

### Added

- Docker compose receives EXPERIMENT_ID and CONFIG_FILE_PATH as env vars, with default values.
- More Documentation.

## [0.1.0] - 2023 - 10 - 27

### Added

- Basic version of Enabler 5 and related components for audio modality using RAVDESS dataset, supporting:
    - Evaluation metrics: confusion matrix, accuracy and f1-scores.
    - Multimodal fusion (Enabler 5): implementing late fusion (decision level fusion).
- Changelog

<!-- 
Example of Categories to use in each release

### Added
- Just an example of how to use changelog.

### Changed
- Just an example of how to use changelog.

### Fixed
- Just an example of how to use changelog.

### Removed
- Just an example of how to use changelog.

### Deprecated
- Just an example of how to use changelog. -->


[unreleased]: https://github.com/XR2Learn/Enabler-5-Inference/compare/v0.6.0...master

[0.1.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.1.0

[0.1.1]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.1.1

[0.2.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.2.0

[0.3.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.3.0

[0.3.1]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.3.1

[0.4.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.4.0

[0.5.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.5.0

[0.6.0]: https://github.com/XR2Learn/Enabler-5-Inference/releases/tag/v0.6.0